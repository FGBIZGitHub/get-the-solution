# Signal Processing introduction

A signal is defined as any physical or virtual quantity that varies with time or space or any other independent variable.

Expressing a signal in a mathematically way, it can be written as a function of an independent variable which varies for example in time. Signals occour in diffrent enviroments and are therefore categorized into the continuous time domain and discret time domain. Furthermore you can distinguish signals into periodically and not periodically signals. 

Signal in continuous time domain are notated

$x(t), 0 ≤ t ≤ T$

Signal in discrete time domain are notated

$x[n], n = 0, 1, · · · , N$

Example Signals: Picture file (discrete), audio file (discrete), voltage, speech (continuous), temperatur sensor, ...

## Signals

![(Fig. 1 discret x[n] (black) and continues signal x(t)(blue))](assets/img/blog/sip/discrete_signal_example_t.png)

There exists infinite types of signals and further more, signals can be composed of each other.
Some special signals are that unique that they get there own name and are described in more detail like the Dirac delta function. As mentioned above there exists periodic signals.
A signal is periodic if its repeats after a certain number of steps. Think of the sin(x) or cos(x) function.

$T...periodic$

## Discret signals

### Impulse signal - Dirac delta function for discret signals

The delta function (or impulse signal) is defined for x[0]=1 and for all other position x[n]=0 (where n!=0).

![(Fig 2. Dirac delta function or impulse function)](assets/img/blog/sip/delta_function.png){ width=240 }

$$\delta[n]=\begin{cases}
1;n=0 \\
0;otherwise
\end{cases}
$$

With the delta function its possible to represent, for example the signal from figure 1, with a sum of delayed and scaled impulses.

### Signal transformations

#### Time shifts using delta function

Transform signal $x[n] -> x[n-n_0]$ where $x[n]=delta[n]$

See the following example with $n_0$=1:

![(Fig 3.)](assets/img/blog/sip/dt_delta_time_shift.png){ width=480 }

The signal is shifted to the right by one which causes a delay.

#### Time reversal

Transform signal $x[n] -> x[-n]$

See the following example:

![(Fig 4.)](assets/img/blog/sip/dt_time_reversal.png){ width=480 }

The signal got mirrored.

#### Scaling using delta function

Transform signal $x[n] -> \alpha\cdotx[n-n_0] ; \alpha\in \mathbb{R}$

![(Fig 5.)](assets/img/blog/sip/dt_scale.png){ width=480 }

#### Even signals

Even signals are defined as $x[n]=x[-n]$ and are symmetic along the Y-Axes.

#### Odd signals

Odd signals are defined as $x[-n]=-x[n]$ and are symmetic along the diagonal.

Its always possible to write any signal as a combination of its even and odd parts.
Its even parts can be computed by $Even\{x[n]\}=\frac{1}{2}\cdot(x[n]+x[-n])$ and its odds parts by
$Odd\{x[n]\}=\frac{1}{2}\cdot(x[n]-x[-n])$.

![(Fig 6.)](assets/img/blog/sip/dt_even_odd_signal.png){ width=480 }

### Basis signal

With the above transformations and signal types we are able to describe signals with the impulse signal (dirac delta function).

See the following example:
$x[n]=(0,1,2,1,1,0,...)$

![(Fig 7.)](assets/img/blog/sip/dt_xn_basis.png){ width=480 }

$x[n]=0\cdot\delta[n+3]+1\cdot\delta[n+2]+2\cdot\delta[n+1]+1\cdot\delta[n]+1\cdot\delta[n-1]+0\cdot\delta[n-2]+...$

The above function is now described with explict terms. We can write more generally:

$x[n]=\sum_{m=\infty}^\infty x[m]\cdot\delta[m-n]$

Sources:

- [Signal and Image Processing lecture]
- [[http://www.songho.ca/dsp/convolution/convolution.html]](http://www.songho.ca/dsp/convolution/convolution.html#decomposition)

## Systems

There exists signal processing systems which can process signals. They consist of a signal input, signal proccessing unit and signal output (Think of the IPO model).

A common wide known discrete-time system is the linear time-invariant (LTI) System.
As the name says its  linear and time-invariant [Source](http://slpl.cse.nsysu.edu.tw/cpchen/courses/dsp/basics-2.pdf). Of course there exists systems for the continous time domain as well, but currently we care only about the discrete-time domain [Source](http://www.dspguide.com/ch5/1.htm).

This system describes in an abstract way what happens if we input a signal x[n] into a system which outputs y[n]. If the system is not a "black box", so we know how the system is "responding" the response is often called h[n].

![(Fig 8.)](assets/img/blog/sip/dt_system_lti.png){ width=480 }

Any signal what you can give to a system (x[n]) is just an accumlation of delayed and scaled impulse.
So if the LTI response to each of this delayed and scaled impulses with a impulse response h[n], then the output y[n] will be a scaled and delayed **sum** of impulse response.
The formula for computing y[n] is the so called discrete-time convolution (operator asterisk).

General convolution defined by:

$y[n]=x[n]*y[n]$

Convolution for a one dimensional signal

$y[n]=\sum_{k=\infty}^\infty x[k]\cdot h[n-k]$

For the online convolution calculator click [here](projects/discret-convolution)

2d convolution is used for example in image processing. For more details checkout [http://www.songho.ca/dsp/convolution/convolution.html#convolution_2d](http://www.songho.ca/dsp/convolution/convolution.html#convolution_2d)

- An LTI System is fully characterized by its impulse response
- The convolution is symmetric $x[n]*h[n]=h[n]*x[n]$
- System can also be characterized by difference equalisation
    - ![(Fig 9.)](assets/img/blog/sip/dt_system_lti_recursive.png){ width=240 }
    - $y[n]=\sum_{l=1}^N a_l\cdot y[n-l]+\sum_{k=0}^u b_k \cdot x[n-k]$
    - Often used when system impulse response is infinite

### System accumulator

$y[n]=\sum_{k=-\infty}^n x[k]$

### Propertie stable system

LTI systems are stable if the absolut sum of there impulse response is finite.

$y[n]=\sum_{n=-\infty}^\infty |h[n]| < \infty$

### Propertie causal system

We call a system causal iff $h[n]=0  ,\forall n <0$

Example in fig 10 shows h[n] as causal and h`[n] as acausal.

![(Fig 10.)](assets/img/blog/sip/acausal_sample.png){ width=240 }

## Discret Fourier Transform

The Fourier transformation is named after Jean Baptiste Joseph Fourier (1768-1830), a French mathematician and physicist. His paper regarding the fourier transformation paper contained that any
continuous periodic signal could be represented as the sum of properly chosen sinusoidal waves [Source: The Scientist and Engineer's Guide to Digital Signal Processing
]. As a signal can be continuous or discrete and signals can be periodic or aperiodic will result in up to four categories.
Lets focus on the discret fourier transformation which is relevant for discret and periodic signals.

A signal can be written as vector for example:

x[n]=(0,1,2,1.8,0.8,-1.8,-2,-1.8,-0.2) N=9.

This signal or the coordinates of it can be rewritten as a sum of decomposed signals using the delta impulses as basis with its coefficients (linear combination with basis elements):

$x[n]=0\cdot\delta[n]+1\cdot\delta[n-1]+2\cdot\delta[n-2]+1.8\cdot\delta[n-2]+...$

Bases allow one to represent vectors by a sequence of scalars called coordinates or components [Source](https://en.wikipedia.org/wiki/Vector_space#Basis_and_dimension).


Sources:

- [Signal and Image Processing lecture]
- [[http://www.songho.ca/dsp/convolution/convolution.html#definition2]](http://www.songho.ca/dsp/convolution/convolution.html#definition2)
- [[http://slpl.cse.nsysu.edu.tw/cpchen/courses/dsp/basics-2.pdf]](http://slpl.cse.nsysu.edu.tw/cpchen/courses/dsp/basics-2.pdf)
- [[http://docs.neu.edu.tr/staff/fahreddin.sadikoglu/3._2.pdf]](http://docs.neu.edu.tr/staff/fahreddin.sadikoglu/3._2.pdf)
