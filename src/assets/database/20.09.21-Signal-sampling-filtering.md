# Sampling

## Sampling frequency

When working with signals, for computers its more convenient and efficent to work with discrete values.
This requires an ability to convert signals from the the continuous time domain to the discrete time domain and visa verce.
As the continues time domain is infinitly, the "sampling technique" provides an ability to make some kind of snapshots of the continuous time signal. The number of occurrences of a repeating event per unit of time[[3]](https://en.wikipedia.org/wiki/Frequency) is the so called frequency.

Definitions of sampling frequency (fs):

SI Unit of frequency: Hz [$s^{-1}$]

$f_s = \frac{AmountOfEvents}{unitOfTime}$

$T_s$ = distanc between samples

$f = \frac{1}{T}$

Note: Sampling frequency is the frequency of taking samples and differs from the signal frequencies.

Example 1:

![Fig. 1. sampling frequency sample](assets/img/blog/sip/sampling_frequency_sample.png)

Notice: Event number 5. is not considered as it belongs to the next "snapshot".

$f_s = \frac{4}{1s}=4Hz$

$T_s = \frac{1}{4s}$

$f = \frac{1}{\frac{1}{4}s}$=4Hz

## Windowing

### Window Design

We have given an infinity long signal and we only observed it in a finite "window".

![(Fig 2. signal and window function)](assets/img/blog/sip/window_design_sample.png){ width=480 }

The observed signal can be retrieved by multiplying the window function with its original signal. The window function can be for instance rectangular one and is outside of the "window" zero. $\hat{x}=w[n]\cdot x[n]$.

![(Fig 3. frequency window function)](assets/img/blog/sip/window_frequency.png){ width=480 }

The specturm of the rectangular window function will result in a sinc function.
Designing window functions result in a trade off. You can choose between stronger desortions for the locally frequencies and weaker desortions for those who are further away. Or you do it the other way around.

Note: You cannot avoid some desortions of your spectrum for the final signal length part. But you can choose by the window function how your spectrum gets distorted.

One of the most popular windows is the [Hann window function](https://en.wikipedia.org/wiki/Hann_function).

Observing a signal for a final length distorts the specturm and may it make difficult to properly resolve all the sepctrums components of the signal. Shorter the signal is the more servier the distortions.

## Sampling signal

Sampling is the process from "converting" a signal from the continues time domain to a discrete time signal. Under certain conditions its possible to reconstruct the continues signal from the discrete signal.

$f_s...sampling frequency$

![(Fig 4. sampling)](assets/img/blog/sip/sampling.png){ width=480 }

With the function S(t) we generate spikes at a fixed time interval in the continues time domain (dirac impulse)

$S(t)=\sum_{\infty}^{n=-\infty} \delta(t-nTs); f_s=1/T_s$

Calculate the discrete time signal $X_s(t)$ by:

$X_s(t)=X(t)*S(t)=\sum_{\infty}^{n=-\infty}  x[n]\cdot \delta(t-nTs)$

x[n]...where we want to sample

$\Omega$...frequency in the continues Time domain (pysical units in Hz)

$\omega$...discrit time series frequency

Calculate the spectrum of $X_s(\Omega)$

$X_s(\Omega)=\frac{1}{T_s}\sum_{\infty}^{k=-\infty} X(\Omega-k\cdot\Omega_s); Omega_s=2\cdot\pi\cdot f_s$

$S(\Omega)=\frac{2\cdot\pi}{T_s}\sum_{k=-\infty}^{\infty}\delta(\Omega-k\cdot\Omega_s)$

From the modulation theorem we know that the spectrum of our sample signal is given by our original signal convoled with our sampling function:

$X_s(\Omega)=X(\Omega)*S(\Omega)$

The specturm of Xs(t) is shifted infinite k-times.

### Nyquist–Shannon sampling theorem

Let X(t) be a bandlimited signal with $X(\Omega)=0 for | \Omega | \geq\Omega_N$.
Then x(t) is uniquely determined by its samples x[n]=(nTs) if the sampling frequeuncy $\Omega_s\geq 2\Omega_N$

For example: Audiofiles. Human is able to hear or recognize noises with a frequencie up to 22kHz. For this reason the signal needs to be sampled with a sampling frequency of 44kHz.

## Relation of Ω and ω

$\Omega\cdot T\cdot s=\omega$

$f=\frac{\omega\cdot f_s}{2\cdot\pi}$

Sample:

Lets assume we have a discrite time signal $X(\omega)$ with a spectrum from $-\pi$ to $\pi$
Now we want to know, to which pysical frequencies $X(\omega)$ is correspondending?

$f_{\omega=\pi}=\frac{\pi\cdot f_s}{2\cdot\pi}=\frac{f_s}{2}$

$f_{\omega=-\pi}=-\frac{f_s}{2}$

This means if we for example sample a signal at 1kHz and compute the DFT and plot the spectrum from $-\pi$ to $\pi$ over the frequencies from -500Hz to + 500Hz.

## Relation of the sampling frequency, window length and the frequency resolution

-> Sampling frequency has no impact to the frequency resolution.

Frequency resolution is determined by its window length

N... length of signal

$frequency-resolution-(pysical)=\frac{f_s}{N}=\frac{f_s}{T\cdot f_s}=\frac{1}{T}$

For example: Record an audiosignal for one 1s. Then the DFT gives gives us a frequency of 1Hz. Record 10s frequency resolution is 0.1Hz. This means we need a certain frequency resolution to resolve osciallations on which we are intressted in. If the recording window is too short than the frequency resolution is maybe to coarse grain to see whats actual going on.

## Resampling

Change the sampling rate after the signal was recorded. For example we want to do that to save storage on the computer.

### Downsampling

Naiv down sampling: by a factor of two we set every second signal to 0 (drop every second sample).
To downsample by an integer factor u, we first have to aplly a lowpass-filter at cut off frequencies $+-\frac{\pi}{u}$, and then compute the new signal $x_d[n]=x_{LowPass}[u\cdot n]$

### Upsampling

For example upsampling signal x[n] by a factor L=2 to the new signal $x_u[n]$.
We need to reconstruct every second signal. We can do that for example with a linear interpolation, which is not a good practice. Better do it with:

$x_u[n]=\sum^{\infty}_{k=-\infty}x[k]\cdot\delta[n-k\cdot L]$

$X_u(\omega)=\sum^{\infty}_{k=-\infty}x[n]\cdot e^{-j\omega\cdot L\cdot k}=X(\omega L)$

Upsampling by creating a new upsampled signal $x_u[n]=\sum^{\infty}_{k=-\infty}x[k]\cdot\delta[n-k\cdot L]$ and than apply low pass filter with cut off frequency $\frac{+\pi}{-L}$.

General Resampling $\frac{L}{u}$: First upsample by L, then downsample by u.

In principal we can resample at any frequncy we like. However there is one small thing to take in consideration. It could be that to resample by one specific fraction we first have to upsample by a very large number L before downlsampling again by a very large numer m and this upsampling takes an extra ordinary amount of memory. If not careful enough you we can run into compution problems.

## Designing Filters

Application:

When recording for example brain signals there can be some "frequency noise". This "noise" we want to filter out. An image (which can also be transformed with the dft) can have frequencies. When taking pictures the sensors of the camera which are computing the pixel also can have some kind of "white noise". For example an image with a blue sky which contains the color blue which is changing to an orange horizon (to capture the sunset). This kind of image would be represented as a slow shift in the amplitude of the brightness of the picture. this means the image has a low frequency and the noise of the sensor which got a high frequency could be filterted out by a low pass filter.

Filtering is also relevant for the classification problems (machine learning).

Radio signals contains all the information from all radio stations. To recieve only the signal of one particular radio station we would need a band pass filter to filter out all other radio stations signals except the one we are intressted.

### Specific ideal filter

We can only approximate an ideal filter.

### Low Pass filter

The low pass filter is a very important filter typ, as any other filter typ can be build up of a sum of low pass filters.
In the following example the transform function of the low pass filter is called $|H(\omega)|$
w_c is the cut of point of the frequency. Ideal low pass filter has a gain of 1 for low frequencies and a gain of 0 for all other frequencies with are larger than our cut of point w_c.

![Fig. 5. ideal low pass filter](assets/img/blog/sip/ideal_low_pass_filter.png){ width=480 }

Ideal filter have zero or linear phase response!

The challenging about a ideal filter response is that its an acausal system (meaining it should response to the signal before it has seen in time (would work only for offline data) ) and got a infinite impulse response.

In practice we want to work with final length filter and for real-time applications causal filters are requried.

Cutting of the acausal part of the filter and cut of the filter of at the length which is suitable but will lead to a filter distortion and will result in a none-ideal filter. As seen below (low pass filter):

![Fig. 6. low pass filter with "Pass band", "transition band", "stop band"](assets/img/blog/sip/low_pass_filter.png){ width=480 }

- $w_c$ cut off frequency
- $w_p$ end of the pass-band
- $w_s$ start of stop-band
- $\delta_1$ peak pass-band ripple $-20db\cdot log_{10}(1-\delta_1)[db]$
- $\delta_2$ peak stop-band ripple $-20db\cdot log_{10}(\delta_2)[db]$

The low pass filter from figure 6. allows a derivation from $1+\delta_1$ and $1-\delta_1$ for the passband and for the stoppband from 0 to $\delta_2$. The transistion phase from the passband to the stoppband, which does not happen instantly, is called transistion band. For example the width of the transistion band ($w_p$ and $w_s$) influnces the steepness of the curve.

As an ideal filter should not delay the signal the ideal phase is 0. As this is reality not possible we want at least a linear phase response. With a linear phase response the signal would be always delayed with the same time number steps.

Lets assume we have $h_{ideal}$ which shifts the signal by $n\cdot d_{delay}$.

$h_{ideal}[n]=\delta[n-n\cdot d_{delay}]$

Make use dft:

$h_{ideal}[n]=\delta[n-n\cdot d_{delay}]\Leftrightarrow \sum_{n=\infty}^{\infty} \delta[n-n\cdot d_{delay}]\cdot e^{-j\cdot \omega n\cdot d_{delay}}$

![Fig. 7. linear phase or phase equal zero"](assets/img/blog/sip/low_pass_filter_linear_phase.png){ width=480 }

If we dont have a linear phase we can try to achieve them with:

1. Use a finite impulse respose filter (FIR-Filter) beause they have a linear phase response (for real time application)
2. If you need to use an infite impulse filter (IIR-Filter) use forward-backward filtering (Can only be used with offline data (signal already recorded)). Can be designed better (compared to FIR-Filter) and have therefore better properties. How does the forward-backward filter work? First filter signal, than flip it in time, so that it runs backward in time and put it again through filter. In the first time the signal got delayed by the phase response and putting the flipped signal again to the filter everything gets advanced. In sum this means that the phase response is canceling itself out, which results in a phase zero response.


